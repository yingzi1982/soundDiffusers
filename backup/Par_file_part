#-----------------------------------------------------------------------------
#
# simulation input parameters
#
#-----------------------------------------------------------------------------

# title of job
title                           = TITLE

# forward or adjoint simulation
# 1 = forward, 2 = adjoint, 3 = both simultaneously
# note: 2 is purposely UNUSED (for compatibility with the numbering of our 3D codes)
SIMULATION_TYPE                 = 1
# 0 = regular wave propagation simulation, 1/2/3 = noise simulation
NOISE_TOMOGRAPHY                = 0
# save the last frame, needed for adjoint simulation
SAVE_FORWARD                    = .false.

# parameters concerning partitioning
NPROC                           = 48
partitioning_method             = 3

# number of control nodes per element (4 or 9)
ngnod                           = 4

# time step parameters
# total number of time steps
NSTEP                           = 300000
# duration of a time step (see section "How to choose the time step" of the manual for how to do this)
DT                              = 3.0d-7


# time stepping
# 1 = Newmark (2nd order), 2 = LDDRK4-6 (4th-order 6-stage low storage Runge-Kutta), 3 = classical RK4 4th-order 4-stage Runge-Kutta
time_stepping_scheme            = 1

# axisymmetric (2.5D) or Cartesian planar (2D) simulation
AXISYM                          = .false.

# set the type of calculation (P-SV or SH/membrane waves)
P_SV                            = .true.

# set to true to use GPUs
GPU_MODE                        = .false.

# creates/reads a binary database that allows to skip all time consuming setup steps in initialization
# 0 = does not read/create database
# 1 = creates database
# 2 = reads database
setup_with_binary_database      = 0

# available models
#   default       - define model using nbmodels below
#   ascii         - read model from ascii database file
#   binary        - read model from binary databse file
#   binary_voigt  - read Voigt model from binary database file
#   external      - define model using define_external_model subroutine
#   gll           - read GLL model from binary database file
#   legacy        - read model from model_velocity.dat_input
MODEL                           = default

# Output the model with the requested type, does not save if turn to default or .false.
# (available output formats: ascii,binary,gll,legacy)
SAVE_MODEL                      = ascii


#-----------------------------------------------------------------------------
#
# attenuation
#
#-----------------------------------------------------------------------------

# attenuation parameters
ATTENUATION_VISCOELASTIC        = .false.
ATTENUATION_VISCOACOUSTIC       = .false.

# for viscoelastic attenuation
N_SLS                           = 2
f0_attenuation                  = 1000
READ_VELOCITIES_AT_f0           = .false.

# for poroelastic attenuation
ATTENUATION_PORO_FLUID_PART     = .false. 
Q0_poroelastic                  = 1
freq0_poroelastic               = 1000

# to undo attenuation for sensitivity kernel calculations or forward runs with SAVE_FORWARD
# use the flag below. It performs undoing of attenuation in an exact way for sensitivity kernel calculations
# but requires disk space for temporary storage, and uses a significant amount of memory used as buffers for temporary storage.
# When that option is on the second parameter indicates how often the code dumps restart files to disk (if in doubt, use something between 100 and 1000).
UNDO_ATTENUATION_AND_OR_PML     = .false.
NT_DUMP_ATTENUATION             = 500


#-----------------------------------------------------------------------------
#
# sources
#
#-----------------------------------------------------------------------------

# source parameters
NSOURCES                        = 1
force_normal_to_surface         = .false.

# use an existing initial wave field as source or start from zero (medium initially at rest)
initialfield                    = .false.
add_Bielak_conditions_bottom    = .false.
add_Bielak_conditions_right     = .false.
add_Bielak_conditions_top       = .false.
add_Bielak_conditions_left      = .false.

# acoustic forcing
ACOUSTIC_FORCING                = .false.


#-----------------------------------------------------------------------------
#
# receivers
#
#-----------------------------------------------------------------------------

# receiver set parameters for recording stations (i.e. recording points)
seismotype                      = 6

# subsampling of the seismograms to create smaller files (but less accurately sampled in time)
subsamp_seismos                 = 1

# so far, this option can only be used if all the receivers are in acoustic elements
USE_TRICK_FOR_BETTER_PRESSURE   = .false.

# use this t0 as earliest starting time rather than the automatically calculated one
USER_T0                         = 0.0d0

# seismogram formats
save_ASCII_seismograms          = .true.
save_binary_seismograms_single  = .false.
save_binary_seismograms_double  = .false.
SU_FORMAT                       = .false.

# use an existing STATION file found in ./DATA or create a new one from the receiver positions below in this Par_file
use_existing_STATIONS           = .true.

# number of receiver sets (i.e. number of receiver lines to create below)
nreceiversets                   = 1

# orientation
anglerec                        = 0.d0
rec_normal_to_surface           = .false. 

# first receiver set (repeat these 6 lines and adjust nreceiversets accordingly)
nrec                            = 1      
xdeb                            = 150000.
zdeb                            = 40000.
xfin                            = 70000.
zfin                            = 0.   
record_at_surface_same_vertical = .false.


#-----------------------------------------------------------------------------
#
# adjoint kernel outputs
#
#-----------------------------------------------------------------------------

# save sensitivity kernels in ASCII format (much bigger files, but compatible with current GMT scripts) or in binary format
save_ASCII_kernels              = .true.


#-----------------------------------------------------------------------------
#
# boundary conditions
#
#-----------------------------------------------------------------------------

# Perfectly Matched Layer (PML) boundaries
# absorbing boundary active or not
PML_BOUNDARY_CONDITIONS         = .true.
NELEM_PML_THICKNESS             = 5
ROTATE_PML_ACTIVATE             = .false.
ROTATE_PML_ANGLE                = 30.
# set to .false. unless you know what you are doing; this implements automatic adjustment of the PML parameters for elongated models.
# The goal is to improve the absorbing efficiency of PML for waves with large incidence angles, but this can lead to artefacts.
# In particular, this option is efficient only when the number of sources NSOURCES is equal to one.
PML_PARAMETER_ADJUSTMENT        = .false.

# Stacey ABC
STACEY_ABSORBING_CONDITIONS     = .false.

# periodic boundaries
ADD_PERIODIC_CONDITIONS         = .false.
PERIODIC_HORIZ_DIST             = 0.3597d0


#-----------------------------------------------------------------------------
#
# velocity and density models
#
#-----------------------------------------------------------------------------

# external tomography file
TOMOGRAPHY_FILE                 = ./DATA/tomo_file.xyz

# use an external mesh created by an external meshing tool or use the internal mesher
read_external_mesh              = .false.


#-----------------------------------------------------------------------------
#
# PARAMETERS FOR EXTERNAL MESHING
#
#-----------------------------------------------------------------------------

# data concerning mesh, when generated using third-party app (more info in README)
# (see also absorbing_conditions above)
mesh_file                       = ./DATA/ice_water_rock_1D/ice_water_rock_1D_elements   # file containing the mesh
nodes_coords_file               = ./DATA/ice_water_rock_1D/ice_water_rock_1D_nodes   # file containing the nodes coordinates
materials_file                  = ./DATA/ice_water_rock_1D/ice_water_rock_1D_material   # file containing the material number for each element
free_surface_file               = ./DATA/ice_water_rock_1D/ice_water_rock_1D_surface_free   # file containing the free surface
axial_elements_file             = ./DATA/axial_elements_file   # file containing the axial elements if AXISYM is true
absorbing_surface_file          = ./DATA/ice_water_rock_1D/ice_water_rock_1D_surface_absorb   # file containing the absorbing surface
acoustic_forcing_surface_file   = ./DATA/MSH/Surf_acforcing_Bottom_enforcing_mesh   # file containing the acoustic forcing surface
absorbing_cpml_file             = ./DATA/absorbing_cpml_file   # file containing the CPML element numbers
tangential_detection_curve_file = ./DATA/courbe_eros_nodes  # file containing the curve delimiting the velocity model

#-----------------------------------------------------------------------------
#
# PARAMETERS FOR INTERNAL MESHING
#
#-----------------------------------------------------------------------------

# file containing interfaces for internal mesh
interfacesfile                  = ./interfaces.dat

# geometry of the model (origin lower-left corner = 0,0) and mesh description
xmin                            = -5.5d0
xmax                            =  5.5d0
nx                              =  1100

# absorbing boundary parameters (see absorbing_conditions above)
absorbbottom                    = .true.
absorbright                     = .true.
absorbtop                       = .true.
absorbleft                      = .true.


#-----------------------------------------------------------------------------
#
# display parameters
#
#-----------------------------------------------------------------------------

# every how many time steps we display information about the simulation (costly, do not use a very small value)
NSTEP_BETWEEN_OUTPUT_INFO       = 5000

# meshing output
output_grid_Gnuplot             = .false.
output_grid_ASCII               = .false.

# to plot total energy curves, for instance to monitor how CPML absorbing layers behave;
# should be turned OFF in most cases because a bit expensive
OUTPUT_ENERGY                   = .false.

# every how many time steps we compute energy (which is a bit expensive to compute)
NTSTEP_BETWEEN_OUTPUT_ENERGY    = 5000

# Compute the field int_0^t v^2 dt for a set of GLL points and write it to file. Use
# the script utils/visualisation/plotIntegratedEnergyFile.py to watch. It is refreshed at the same time than the seismograms
COMPUTE_INTEGRATED_ENERGY_FIELD = .false.

#-----------------------------------------------------------------------------
#
# movies/images/snaphots
#
#-----------------------------------------------------------------------------

# every how many time steps we draw JPEG or PostScript pictures of the simulation
# and/or we dump results of the simulation as ASCII or binary files (costly, do not use a very small value)
NSTEP_BETWEEN_OUTPUT_IMAGES     = 1000

# minimum amplitude kept in % for the JPEG and PostScript snapshots; amplitudes below that are muted
cutsnaps                        = 1.

#### for JPEG color images ####
output_color_image              = .false.         # output JPEG color image of the results every NSTEP_BETWEEN_OUTPUT_IMAGES time steps or not
imagetype_JPEG                  = 3              # display 1=displ_Ux 2=displ_Uz 3=displ_norm 4=veloc_Vx 5=veloc_Vz 6=veloc_norm 7=accel_Ax 8=accel_Az 9=accel_norm 10=pressure
factor_subsample_image          = 1.0d0          # (double precision) factor to subsample or oversample (if set to e.g. 0.5) color images output by the code (useful for very large models, or to get nicer looking denser pictures)
USE_CONSTANT_MAX_AMPLITUDE      = .false.        # by default the code normalizes each image independently to its maximum; use this option to use the global maximum below instead
CONSTANT_MAX_AMPLITUDE_TO_USE   = 1.17d4         # constant maximum amplitude to use for all color images if the above USE_CONSTANT_MAX_AMPLITUDE option is true
POWER_DISPLAY_COLOR             = 0.30d0         # non linear display to enhance small amplitudes in JPEG color images
DRAW_SOURCES_AND_RECEIVERS      = .true.         # display sources as orange crosses and receivers as green squares in JPEG images or not
DRAW_WATER_IN_BLUE              = .true.         # display acoustic layers as constant blue in JPEG images, because they likely correspond to water in the case of ocean acoustics or in the case of offshore oil industry experiments (if off, display them as greyscale, as for elastic or poroelastic elements, for instance for acoustic-only oil industry models of solid media)
USE_SNAPSHOT_NUMBER_IN_FILENAME = .false.        # use snapshot number in the file name of JPEG color snapshots instead of the time step (for instance to create movies in an easier way later)

#### for PostScript snapshots ####
output_postscript_snapshot      = .false.        # output Postscript snapshot of the results every NSTEP_BETWEEN_OUTPUT_IMAGES time steps or not
imagetype_postscript            = 1              # display 1=displ vector 2=veloc vector 3=accel vector; small arrows are displayed for the vectors
meshvect                        = .true.         # display mesh on PostScript plots or not
modelvect                       = .false.        # display velocity model on PostScript plots or not
boundvect                       = .true.         # display boundary conditions on PostScript plots or not
interpol                        = .true.         # interpolation of the PostScript display on a regular grid inside each spectral element, or use the non-evenly spaced GLL points
pointsdisp                      = 6              # number of points in each direction for interpolation of PostScript snapshots (set to 1 for lower-left corner only)
subsamp_postscript              = 1              # subsampling of background velocity model in PostScript snapshots
sizemax_arrows                  = 1.d0           # maximum size of arrows on PostScript plots in centimeters
US_LETTER                       = .false.        # use US letter or European A4 paper for PostScript plots

#### for wavefield dumps ####
output_wavefield_dumps          = .true.        # output wave field to a text file (creates very big files)
imagetype_wavefield_dumps       = 4              # display 1=displ vector 2=veloc vector 3=accel vector 4=pressure
use_binary_for_wavefield_dumps  = .false.        # use ASCII or single-precision binary format for the wave field dumps

#-----------------------------------------------------------

# Ability to run several calculations (several earthquakes)
# in an embarrassingly-parallel fashion from within the same run;
# this can be useful when using a very large supercomputer to compute
# many earthquakes in a catalog, in which case it can be better from
# a batch job submission point of view to start fewer and much larger jobs,
# each of them computing several earthquakes in parallel.
# To turn that option on, set parameter NUMBER_OF_SIMULTANEOUS_RUNS to a value greater than 1.
# To implement that, we create NUMBER_OF_SIMULTANEOUS_RUNS MPI sub-communicators,
# each of them being labeled "my_local_mpi_comm_world", and we use them
# in all the routines in "src/shared/parallel.f90", except in MPI_ABORT() because in that case
# we need to kill the entire run.
# When that option is on, of course the number of processor cores used to start
# the code in the batch system must be a multiple of NUMBER_OF_SIMULTANEOUS_RUNS,
# all the individual runs must use the same number of processor cores,
# which as usual is NPROC in the Par_file,
# and thus the total number of processor cores to request from the batch system
# should be NUMBER_OF_SIMULTANEOUS_RUNS * NPROC.
# All the runs to perform must be placed in directories called run0001, run0002, run0003 and so on
# (with exactly four digits).
#
# Imagine you have 10 independent calculations to do, each of them on 100 cores; you have three options:
#
# 1/ submit 10 jobs to the batch system
#
# 2/ submit a single job on 1000 cores to the batch, and in that script create a sub-array of jobs to start 10 jobs,
# each running on 100 cores (see e.g. http://www.schedmd.com/slurmdocs/job_array.html )
#
# 3/ submit a single job on 1000 cores to the batch, start SPECFEM2D on 1000 cores, create 10 sub-communicators,
# cd into one of 10 subdirectories (called e.g. run0001, run0002,... run0010) depending on the sub-communicator
# your MPI rank belongs to, and run normally on 100 cores using that sub-communicator.
#
# The option below implements 3/.
#
NUMBER_OF_SIMULTANEOUS_RUNS     = 1

# if we perform simultaneous runs in parallel, if only the source and receivers vary between these runs
# but not the mesh nor the model (velocity and density) then we can also read the mesh and model files
# from a single run in the beginning and broadcast them to all the others; for a large number of simultaneous
# runs for instance when solving inverse problems iteratively this can DRASTICALLY reduce I/Os to disk in the solver
# (by a factor equal to NUMBER_OF_SIMULTANEOUS_RUNS), and reducing I/Os is crucial in the case of huge runs.
# Thus, always set this option to .true. if the mesh and the model are the same for all simultaneous runs.
# In that case there is no need to duplicate the mesh and model file database (the content of the DATABASES_MPI
# directories) in each of the run0001, run0002,... directories, it is sufficient to have one in run0001
# and the code will broadcast it to the others)
BROADCAST_SAME_MESH_AND_MODEL   = .true.

